{"cells":[{"cell_type":"markdown","metadata":{"id":"BHzfMHbFqIKi"},"source":["# ClusterAI 2022\n","\n","# Ciencia de Datos - Ingeniería Industrial - UTN BA\n","\n","# clase_09: Practica Redes Neuronales\n","\n","### Elaborado por: Aguirre Nicolas"]},{"cell_type":"markdown","metadata":{"id":"S8Y4IUeNrTH4"},"source":["# IMPORTS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zj2VEgN6qjDJ"},"outputs":[],"source":["import tensorflow as tf #Libreria de Redes Neronales\n","from  tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.models import Sequential\n","\n","print(tf.__version__)\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","pd.set_option('display.float_format', lambda x: '%.1d' % x) # Para acotar los decimales en pandas"]},{"cell_type":"markdown","metadata":{"id":"shZj2OGKs0Hl"},"source":["# IRIS DATASET\n","\n","En esta primera ejercitacion vamos a retomar el dataset Iris (visto en la Clase 4)\n","\n","\n","El conjunto de datos contiene 50 muestras de cada una de tres especies de Iris (Iris setosa, Iris virginica e Iris versicolor). Se midió cuatro rasgos de cada muestra: lo largo y lo ancho del sépalos y pétalos, en centímetros. Basado en la combinación de estos cuatro rasgos.\n","\n","https://es.wikipedia.org/wiki/Iris_flor_conjunto_de_datos\n","\n","Los datos son:\n","\n","| Columna | Descripcion |\n","| --- | --- |\n","| ID | Unique ID |\n","| SepalLengthCm | Length of the sepal (cm) |\n","| SepalWidthCm | Width of the sepal (cm) |\n","| PetalLengthCm | Length of the petal (cm) |\n","| PetalWidthCm | Width of the petal (cm) |\n","| Species | name |\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GxUnNijVsmww"},"outputs":[],"source":["# Primero cargamos los datos que ya vienen incluidos en la libreria sk-learn.\n","from sklearn.datasets import load_iris\n","iris = load_iris()\n","\n","X = iris.data\n","Y = iris.target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIbBihoeU95Q"},"outputs":[],"source":["n_features = np.shape(X)[0]\n","n_samples = np.shape(X)[1]\n","n_classes = np.unique(Y)\n","print(f'Features: ',n_samples)\n","print(f'Samples: ',n_features)\n","print(f'Classes: ',n_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hhudQ_Xs1yL"},"outputs":[],"source":["# Veamos la primera sample\n","print(f'X: {X[0]}')\n","print(f'Y: {Y[0]}')"]},{"cell_type":"markdown","metadata":{"id":"--P7frv5qX51"},"source":["## SPLIT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSP2IQWiq91_"},"outputs":[],"source":["# Separamos train y test set\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"SFMeW20jqa52"},"source":["## SCALING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UReu6invWAGg"},"outputs":[],"source":["# Noralizamos\n","scaler = preprocessing.StandardScaler()\n","scaler.fit(x_train)\n","x_train_norm = scaler.transform(x_train)\n","x_test_norm = scaler.transform(x_test)"]},{"cell_type":"markdown","metadata":{"id":"5_0s6Pm5R7Wj"},"source":["# MODELO"]},{"cell_type":"markdown","metadata":{"id":"bdA_6opHYD3g"},"source":["Dentro de la libreria TensorFlow-Keras, existen dinstas manera de definir los modelos de Redes Neuronales (NN). El mas directo y sensillo es la arquittectura 'Sequential'.\n","\n","En ella, el **foreward pass** se define, como su nombre lo indica, de manera secuencial con respecto a las capas (layers) que iremos agregando.\n","\n","En primera instancia debemos crear el modelo al que le iremos luego añadiendo las capas. Para esto, creamos un objecto con **tf.keras.models.Sequential()**. Este objeto tiene internamente un metodo llamado *.add()* que ira añadiendo las capas que iremos pasando."]},{"cell_type":"markdown","metadata":{"id":"tHNWAPpQY303"},"source":["\n","\n","---\n","\n","**.add()**\n","```python\n","model = tf.keras.models.Sequential()\n","# Input Layer\n","model.add(Dense( D_1, input_dim = 4, activation = 'ZZZ') )\n","\n","# Hidden Layers\n","model.add(Dense( D_2, activation = 'ZZZ') )\n","...\n","model.add(Dense( D_n, activation = 'ZZZ') )\n","\n","\n","# Output Layer\n","model.add(Dense( D_o, activation = 'ZZZ') )\n","\n","```\n","---\n","\n","Tambien podemos pasarle dentro de una lista de python las capas que componen el modelo.\n","\n","**Lista de layers**\n","\n","```python\n","model = tf.keras.models.Sequential([\n","  \n","  # Input Layer\n","  Dense( D_1, input_dim = 4, activation = 'ZZZ'),\n","\n","  # Hidden Layers\n","  Dense( D_2, activation = 'ZZZ'),  \n","  Dense( D_3, activation = 'ZZZ'),\n","  ...\n","\n","# Output Layer\n","  Dense( D_o, activation = 'ZZZ' )\n","])\n","```\n","---\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvToMnXsR59t"},"outputs":[],"source":["# Para eliminar los modelos que hayan quedado guardados en memoria\n","tf.keras.backend.clear_session() \n","\n","model = Sequential([\n","  # Primera capa de la red\n","  Dense(4,input_dim=4, activation='sigmoid'),\n","  # Hidden Layers\n","  Dense(4, activation='sigmoid'), \n","  Dense(4, activation='sigmoid'),\n","  # Salida de la red\n","  Dense(3, activation='softmax')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zYqu1KjoTMTM"},"outputs":[],"source":["#Veamos la arquitectura de nuestro modelo\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"YQ8qlAK6wKKn"},"source":["**Consultas?**"]},{"cell_type":"markdown","metadata":{"id":"mVk0MBmVbgrr"},"source":["## Ejemplo de salida del modelo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Imaginemos ahora 2 muestras\n","y_true_example = [0, 2]\n","\n","# Para las cuales la red genera la siguiente salida del 'softmax'\n","\n","y_pred_example = [[0.40, 0.30, 0.30], # Bien Clasificado\n","                  [0.01, 0.50, 0.49]] # Mal Clasificado\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Idk64GcfHkh"},"outputs":[],"source":["# Veamos como varia la loss en base a las predicciones de la red\n","loss_func = SparseCategoricalCrossentropy(reduction='none')\n","# El None en la reduccion, es para obtener la loss individualmente.\n","# Tiene otros usos, pero escapan al curso.\n","\n","# Ahora veamos como daria la loss en cada caso:\n","loss_func(y_true_example, y_pred_example).numpy()"]},{"cell_type":"markdown","metadata":{},"source":["**Bien classificado**\n","$$\n","\\begin{align}\n","\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}}) & = -\\sum_{c=0}^{M=2}y_{0,c}\\log(p_{0,c}) & = - \\bigg( y_{0,0}\\log(p_{0,0}) + y_{0,1}\\log(p_{0,1}) + y_{0,2}\\log(p_{0,2})\\bigg)\\\\\n"," & & = - \\bigg( 1\\times\\log(0.4) + 0\\times\\log(0.3) + 0\\times\\log(0.3)\\bigg)\\\\\n","\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}})  & =  - \\log(0.4)&\\\\\n","\\end{align}\n","$$\n","\n","**Mal classificado**\n","$$\n","\\begin{align}\n","\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}}) & = -\\sum_{c=0}^{M=2}y_{1,c}\\log(p_{0,c}) & = - \\bigg( y_{1,0}\\log(p_{1,0}) + y_{1,1}\\log(p_{1,1}) + y_{1,2}\\log(p_{1,2})\\bigg)\\\\\n"," & & = - \\bigg( 0\\times\\log(0.01) + 0\\times\\log(0.5) + 1\\times\\log(0.49)\\bigg)\\\\\n","\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}})  & =  - \\log(0.49)&\\\\\n","\\end{align}\n","$$\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(-np.log(0.40))\n","print(-np.log(0.49))"]},{"cell_type":"markdown","metadata":{"id":"uZo1biPtbzk3"},"source":["**Consultas?**"]},{"cell_type":"markdown","metadata":{"id":"VfO-L2h0ispn"},"source":["## Optimizador & Funcion de Penalizacion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S972oYbRR6CX"},"outputs":[],"source":["# Optimizador\n","lr = 0.001\n","opt = SGD(learning_rate=lr)\n","# Funcion de penalizacion\n","# Usar ésta loss cuando tenemos un problema multi-class.\n","loss_func = SparseCategoricalCrossentropy()"]},{"cell_type":"markdown","metadata":{"id":"wFhX407_qiOt"},"source":["## COMPILE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFcfsX8yR6AB"},"outputs":[],"source":["# Hasta este momento, hemos definido los elementos que conformaran el modelo.\n","# [arquitectura, optimizer, loss function].\n","# Internamente, estuvimos armando un 'grafo computacional', el cual debe\n","# compilarse.\n","model.compile(optimizer = opt,\n","              loss = loss_func,\n","              metrics = ['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"9edbzpJipAuT"},"source":["# TRAINING"]},{"cell_type":"markdown","metadata":{"id":"UT5d6i7zXHZU"},"source":["<img src=\"https://drive.google.com/uc?id=1d7Rq5FsmQNWcP8T1KGi_TodL49jCEKnY\" width=\"1200\">"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctHeE-CSR57M"},"outputs":[],"source":["# Batch Size\n","bs = 8\n","# Epochs de entrenamiento\n","epochs_training = 300\n","# Entrenamos!\n","training = model.fit(x_train_norm,y_train,epochs=epochs_training,validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"TIIfBp2JcnWb"},"source":["## HISTORY"]},{"cell_type":"markdown","metadata":{"id":"P9Kn8wToc2PT"},"source":["El historial de entrenamiento queda guardado dentro de un diccionario en\n","training.history.\n","\n","Deseamos ver como fue el progreso de neustro entrenamiento epochs por epoch en terminos de la loss_fuction y el accuracy.\n","\n","Si al momento de compilar el modelo le pasamos mas metricas, quedaran guardadas tambien."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XsQd_pkYUhOI"},"outputs":[],"source":["# El historial de entrenamiento quedó guardado en \n","# 'history.history', ingresamos como 'key' cada una de las metricas que queremos plotear.\n","\n","#Loss\n","loss_history = training.history['loss']\n","val_loss_hist = training.history['val_loss']\n","\n","#Accuracy\n","train_acc_history = training.history['accuracy']\n","val_acc_hist = training.history['val_accuracy']\n","epochs = range(1, len(loss_history) + 1)\n","\n","fig, axs = plt.subplots(1,2,figsize=(16,6))\n","axs[0].plot(epochs, loss_history, 'b', label='Train loss')\n","axs[0].plot(epochs, val_loss_hist, 'r', label='Val loss')\n","axs[0].set_title('Training and validation Loss',fontsize=20)\n","axs[0].legend(fontsize=16)\n","axs[1].plot(epochs, train_acc_history, 'b', label='Train Accuracy')\n","axs[1].plot(epochs, val_acc_hist, 'r', label='Validation Accuracy')\n","axs[1].set_title('Training and validation Loss',fontsize=20)\n","axs[1].legend(fontsize=16)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"QfVezoGyog6_"},"source":["## TEST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8WW5ellR2KG"},"outputs":[],"source":["model.evaluate(x_test_norm, y_test,verbose=2)"]},{"cell_type":"markdown","metadata":{"id":"8mTOia-RwliQ"},"source":["## CONFUSION MATRIX"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWdjU9JVtKXP"},"outputs":[],"source":["y_hat = model.predict(x_test_norm) # Salida de la red\n","y_pred = np.argmax(y_hat, axis=1) # Clase de la salida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PDrWjyHttHBJ"},"outputs":[],"source":["cm = confusion_matrix(y_test, y_pred)\n","df_cm = pd.DataFrame(cm, index = np.arange(0,3),columns = np.arange(0,3))\n","plt.figure(figsize = (10,10))\n","sns.heatmap(df_cm, annot=True, cmap='jet',fmt='g')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"79yqU-Uunu5O"},"source":["# **PREGUNTAS**:\n","```\n","1) Es correcto que nuestra loss de train y de validacion disminuyan, y sin embargo el accuracy se mantenga igual/baje ? Por que ? \n","\n","2) Que cambios podriamos hacer para intentar solucionar el entrenamiento con la sigmoid function?\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ge6vUpbrl22s"},"source":["# MNIST DATASET"]},{"cell_type":"markdown","metadata":{"id":"2vVIzXBal5Jr"},"source":["**Este dataset esta compuesto por 70.000 imagenes digitos (28 x 28 pixeles) del 0 al 9.**\n","\n","**El objetivo es claisifcar correctamente los digitos de cada imagen.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWCxBKlrgqNC"},"outputs":[],"source":["# Cargamos el dataset desde la libreria de TF\n","mnist = tf.keras.datasets.mnist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A16wA-VjgjhS"},"outputs":[],"source":["# Viene previamente dividido en train y test \n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","print(f'Shape del x_train: {np.shape(x_train)}')\n","print(f'Shape del y_train: {np.shape(y_train)}')\n","print(f'Shape del x_test: {np.shape(x_test)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVcoTO-QgzkL"},"outputs":[],"source":["# Veamos algunas muestras\n","sample = np.random.randint(0,q_train)\n","plt.figure(figsize=(10,10))\n","for i in range(sample,sample+25):\n","    plt.subplot(5,5,i-sample+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(x_train[i], cmap='gray')\n","    plt.xlabel(y_train[i])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"0Drr6p0BnHtj"},"source":["## SCALING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PPRNU8xglEk"},"outputs":[],"source":["# El valor esta en el rango [0-255]\n","# Vamos a pasarlos al rango [0-1]\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0"]},{"cell_type":"markdown","metadata":{"id":"CO6uHU22nLd2"},"source":["## MODELO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5S-dF8-oJN8"},"outputs":[],"source":["# Definicion del modelo:\n","model = tf.keras.models.Sequential([\n","  # Input layer\n","  # Pasamos de un input de forma 1x28x28 --> 1x784\n","  Flatten(input_shape=(28, 28)),  \n","  \n","  # Hidden Layers\n","    #######################\n","    #------COMPLETAR------#\n","    #######################\n","  \n","  # Output Layers\n","    #######################\n","    #------COMPLETAR------#\n","    #######################\n","])"]},{"cell_type":"markdown","metadata":{"id":"a4MpcuMDo2oG"},"source":["## OPTIMIZER, LOSS FUNCTION & COMPILE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EoseRK2MjJ7E"},"outputs":[],"source":["# Otpimizador\n","  #######################\n","  #------COMPLETAR------#\n","  #######################\n","\n","# Loss Function\n","  #######################\n","  #------COMPLETAR------#\n","  #######################\n","\n","# Compilar\n","model.compile(\n","    \n","  #######################\n","  #------COMPLETAR------#\n","  #######################\n",")  "]},{"cell_type":"markdown","metadata":{"id":"ejsjfHeYnQIY"},"source":["## TRAINING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"McWxTFZvjlqc"},"outputs":[],"source":["# Entrenamiento\n","# Batch Size & Epochs\n","bs = \n","epochs_train = \n","  #######################\n","  #------COMPLETAR------#\n","  #######################\n","training = "]},{"cell_type":"markdown","metadata":{"id":"QjHdu2w_nSdn"},"source":["## HISTORY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jP6ZQscLnVdl"},"outputs":[],"source":["#######################\n","#------COMPLETAR------#\n","#######################"]},{"cell_type":"markdown","metadata":{"id":"cCCG5wuOnWag"},"source":["## TEST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lppq312vnXhp"},"outputs":[],"source":["#######################\n","#------COMPLETAR------#\n","#######################"]},{"cell_type":"markdown","metadata":{"id":"9KPpGS39pxnN"},"source":["## CONFUSION MATRIX"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2FRvDE2psON"},"outputs":[],"source":["y_hat = model.predict(x_test) # Salida de la red\n","y_pred = np.argmax(y_hat, axis=1) # Clase de la salida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s06ZcFC0sIWI"},"outputs":[],"source":["cm = confusion_matrix(y_test, y_pred)\n","df_cm = pd.DataFrame(cm, index = np.arange(0,10),columns = np.arange(0,10))\n","plt.figure(figsize = (15,15))\n","sns.heatmap(df_cm, annot=True, cmap='jet',fmt='g')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"8H9fEDB6Ovwv"},"source":["# TensorFlow-Keras vs PyTorch"]},{"cell_type":"markdown","metadata":{"id":"XtGQlz1jOtj6"},"source":["![](https://www.springboard.com/library/static/ebeb926c35f127358173939193a284c7/29007/pytorch-vs-tensorflow-springboard.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGm6VjuDOu3w"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["BHzfMHbFqIKi"],"name":"clusterai2021_clase09_Redes_Neuronales_Clasifacion_TensorFlow","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.9.13 ('PhD')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"4c3760444b418b510111f445cc2c46200fe77d738ac8bb8298f5c5cbe546de8e"}}},"nbformat":4,"nbformat_minor":0}
